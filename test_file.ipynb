{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ec9645-994c-48eb-83fe-1353d8d28a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "import urllib\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from requests.exceptions import ChunkedEncodingError\n",
    "import os\n",
    "import json\n",
    "import yadisk\n",
    "from datetime import datetime, date, timedelta\n",
    "import locale\n",
    "from time import sleep\n",
    "import shutil\n",
    "import gc\n",
    "import turbodbc\n",
    "from turbodbc import connect\n",
    "import gc\n",
    "from pandas.api.types import is_string_dtype\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import pyodbc\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "import config\n",
    "from yandex_disk_func import *\n",
    "# from parse_functions import *\n",
    "\n",
    "\n",
    "\n",
    "# # указываем путь и название файла с токеном для Яндекс Диск\n",
    "file_path = r'C:\\Users\\o.bogomolov\\Desktop\\Jupyter_notebook\\38_x5_report_parser'\n",
    "\n",
    "public_key = config.public_key # обычная ссылка на доступ к папке одного данного ФЛАЙТА из личного кабинета\n",
    "\n",
    "# забираем список папок в нужной нам директории\n",
    "res = get_yandex_disk_folders(public_key)\n",
    "yandex_folders = res.json() # парсим ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "161bc03c-7528-4267-afb3-77a959c63d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Включаем отображение всех колонок\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Задаем ширину столбцов по контенту\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a48357-4332-403f-9371-9242811751e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d99e039-3857-44da-a335-3d8ecec1af91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Доставка\n",
      "/Перекресток\n",
      "/Пятерочка\n"
     ]
    }
   ],
   "source": [
    "public_key = yandex_folders['public_key']  # из ответа Яндекс забираем public_key, чтобы использовать его для скачивания файлов\n",
    "\n",
    "for i in range(len(yandex_folders['_embedded']['items'])): # через цикл проходим по ответу Яндекса и забираем названия вложенных папок\n",
    "    file_type = yandex_folders['_embedded']['items'][i]['type']\n",
    "    if file_type=='dir':   # если находим файлы с типом dir (папка), то забираем путь к этой папке\n",
    "        folder_path = yandex_folders['_embedded']['items'][i]['path']\n",
    "        print(folder_path)\n",
    "        # yandex_responce = get_yandex_disk_responce(base_public_url, public_key, folder_path) # отправляем запрос, чтобы получить содержимое папки\n",
    "\n",
    "        # # Через цикл проходим по папке с файлами\n",
    "        # # Нас интересуют файлы эксель. Причем каждая экселька будет парситься по своему, т.к. они относятся к разным рекламным площадкам\n",
    "        \n",
    "        # # Проходим через цикл по содержимому папки (отдельный флайт)\n",
    "        # for i in range(len(yandex_responce['_embedded']['items'])):\n",
    "        #     file_info = yandex_responce['_embedded']['items'][i]\n",
    "        #     if file_info['type']=='file':  # если документ является фалйом(не папкой или изображением), то забираем его название \n",
    "        #         file_name = file_info['name'] # сохраняем название файла\n",
    "        #         if 'xls' in file_name: # еслит тип файла является xlsx, то уберем расширение и будем его использовать в качесвте названия отчета\n",
    "        #             file_path = file_info['path']\n",
    "                    \n",
    "        #             # report_name = '.'.join(file_name.split('.')[:-1]) # убираем .xlsx из названия файла\n",
    "        #             print(file_name)\n",
    "        #             res_file_link = get_yandex_disk_responce(download_url, public_key, file_path) # получаем ссылку на скачивание отчета\n",
    "        #             download_response = requests.get(res_file_link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72300c65-9a91-4fae-ac0b-e42eb32378fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_link = download_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2c698f-ed11-41c0-afa7-3c6ee4cd1bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_names = pd.ExcelFile(BytesIO(data_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a60205c-19ba-41b8-8c6d-bc3b8122e902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a69270-d25d-46da-89b1-964873a033d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_names.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946b2620-babe-4af7-a290-bc8f8422f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'test'\n",
    "report_name = 'tst'\n",
    "tmp_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2ba58f-f515-4a04-8842-35ebe4650a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet_name in sheet_names.sheet_names:\n",
    "    if 'mediaplan' in sheet_name:\n",
    "        df = pd.read_excel(BytesIO(data_link), sheet_name=sheet_name, header=None)\n",
    "        \n",
    "        # приводим в порядок название листа, чтобы его записать в новую таблицу\n",
    "        sheet_name = normalize_headers(sheet_name)\n",
    "        print(f'    {sheet_name}')\n",
    "        \n",
    "        # заполняем вниз название истоника и аудитории\n",
    "        ffill_columns = [1, 2]\n",
    "        df[ffill_columns] = df[ffill_columns].ffill() # заполняем вниз\n",
    "        # заполяем вниз rotation type - здесь объединенная ячейка, и в этом поле нет названия\n",
    "        # чтобы оно появилось, заранее протягиваем вниз это название\n",
    "        df[8] = df[8].fillna('rotation type')\n",
    "        # заполняем вниз объединенные ячейки\n",
    "        df = df.fillna('')\n",
    "        \n",
    "        # сохраняем название бренда\n",
    "        brand = df[3].loc[get_index_row(df, 2, 'brand')] \n",
    "        # сохраняем период\n",
    "        period = df[3].loc[get_index_row(df, 2, 'период')]\n",
    "        \n",
    "    \n",
    "        # забираем индекс начала таблицы\n",
    "        start_index = get_index_row(df, 1, 'category')\n",
    "        # задаем названия полей\n",
    "        df.columns = df.iloc[start_index].apply(normalize_headers) # забираем название полей из файла\n",
    "        # обрезаем верхнюю часть таблицы. она больше не нужна\n",
    "        df = df.iloc[start_index+2:].reset_index(drop=True)\n",
    "        # забираем окончание таблицы\n",
    "        end_index = get_index_row(df, 'category', 'total')\n",
    "        # обрезаем таблицу снизу\n",
    "        df = df.iloc[:end_index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c176f39d-52e4-46d9-9558-8c8c9d5fe981",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf5042c-1cb6-4ed8-af64-0f56b94d2e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16f3dd0-d397-4327-a429-b18b2d369d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a04344-0a6e-42cf-9469-0c4db14f7733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ade934-1f30-4dcb-88ad-79876bc5f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# источник FirstData\n",
    "# типы размещения Видео и Баннерная реклама\n",
    "# Функция для обработки медиаплана \n",
    "# 1. Медиаплан для обработки находится на листе Plan_Media \n",
    "# 2. В столбике B  находится слово Brand справа от него в столбике C название Бренда\n",
    "# 3. В столбике B  находится слово Period справа от него в столбике C название указан период медиаплана\n",
    "# 4. В столбике B  должно находиться поле Source\n",
    "# 5. Каждая таблица должна заканчиваться строкой итогов \n",
    "# 6. В столбике С находятся Таргетинги - Targeting by purchase \n",
    "# 7. В столбике I находится тип размещения (CPC, CPM)\n",
    "\n",
    "def get_firstdata_mediaplan(data_link, network, report_name):\n",
    "    tmp_dict = {}\n",
    "    sheet_names = pd.ExcelFile(BytesIO(data_link))\n",
    "    for sheet_name in sheet_names.sheet_names:\n",
    "        if 'mediaplan' in sheet_name:\n",
    "            df = pd.read_excel(BytesIO(data_link), sheet_name=sheet_name)\n",
    "            # приводим в порядок название листа, чтобы его записать в новую таблицу\n",
    "            sheet_name = normalize_headers(sheet_name)\n",
    "            print(f'    {sheet_name}')\n",
    "            # заполняем вниз название истоника\n",
    "            df['Unnamed: 1'] = df['Unnamed: 1'].ffill()\n",
    "            # заполняем вниз таргетинги\n",
    "            df['Unnamed: 2'] = df['Unnamed: 2'].ffill()\n",
    "            # заполяем вниз rotation type - здесь объединенная ячейка, и в этом поле нет названия\n",
    "            # чтобы оно появилось, заранее протягиваем вниз это название\n",
    "            df['Unnamed: 8'] = df['Unnamed: 8'].fillna('rotation type')\n",
    "            # заполняем вниз объединенные ячейки\n",
    "            df = df.fillna('')\n",
    "            \n",
    "            # сохраняем название бренда\n",
    "            brand = df['Unnamed: 3'].loc[get_index_row(df, 'Unnamed: 2', 'brand')] \n",
    "            # сохраняем период\n",
    "            period = df['Unnamed: 3'].loc[get_index_row(df, 'Unnamed: 2', 'период')]\n",
    "            # забираем индекс начала таблицы\n",
    "            start_index = get_index_row(df, 'Unnamed: 1', 'category')\n",
    "            \n",
    "            # задаем названия полей\n",
    "            df.columns = df.iloc[start_index].apply(normalize_headers) # забираем название полей из файла\n",
    "            # обрезаем верхнюю часть таблицы. она больше не нужна\n",
    "            df = df.iloc[start_index+2:].reset_index(drop=True)\n",
    "            # забираем окончание таблицы\n",
    "            end_index = get_index_row(df, 'category', 'total')\n",
    "            # обрезаем таблицу снизу\n",
    "            df = df.iloc[:end_index].reset_index(drop=True)\n",
    "            # создаем базовый список полей, которые есть всегда вне зависимости от типа размещения\n",
    "            standart_columns = ['category', 'targeting by purchase', 'format', 'period', \n",
    "                            'price list cost (cost per unit) net ', 'rotation type',\n",
    "                            'total price list cost net', 'reach forecast (uu)', 'frequency total till',\n",
    "                            'impressions', 'clicks']\n",
    "            # проверяем наличие Видео размещений. Если они есть, то используем дополнительные поля из таблицы\n",
    "            # если Видео размещений нет, то добавляем дополнительно 2 поля с 0 (это нужно для нормализации общей таблицы     \n",
    "            if 'vtr,%' not in list(df.columns):\n",
    "                df['number of views'] = 0\n",
    "                df['vtr,%'] = 0.0\n",
    "                \n",
    "            standart_columns += ['number of views', 'vtr,%']\n",
    "            # оставляем только нужные поля\n",
    "            df = df[standart_columns]\n",
    "            # приводим названия полей к единому стандарту\n",
    "            df = df.rename(columns={'category': 'source', 'targeting by purchase': 'targeting', 'format': 'ad copy format', \n",
    "                                     'price list cost (cost per unit) net ': 'unit price', \n",
    "                                    'frequency total till': 'frequency', 'reach forecast (uu)': 'reach', \n",
    "                                    'total price list cost net' :'budget_without_nds', 'number of views': 'views', 'vtr,%': 'vtr, %'})\n",
    "    \n",
    "            # некоторые типы размещений имеют объединенные строки\n",
    "            # например Баннер и универсальный баннер - это 2 строки с объединенными ячейками по расходам, показам и тд.\n",
    "            # поэтому создадим доп. поле, где соединим их названия в одну строку\n",
    "            # создаем пустое поле\n",
    "            df['merge_type_cells'] = ''\n",
    "            # проходим через цикл по датаФрейму\n",
    "            # в первой строке по определению не может быть данных, поэтому сохраняем там название формата\n",
    "            # если это не первая и не посленяя строка, то нам нужно провести проверку\n",
    "            # допустим мы находимся в строке номер 2\n",
    "            # мы проверяем, что находится в строке номер 3 в поле rotation type (на первых шагах мы сделали заполнение вниз)\n",
    "            # соответсвенно если ячейка была пустая, там появится надпись rotation type - так мы поймем, что это как раз объединенные данные\n",
    "            # берем название формата из текущей строки и добавляем к нему название формата из следующей строки\n",
    "            # во всех остальных случаях просто возвращаем название формата из текущей строки\n",
    "            for i in range(len(df)):\n",
    "                base_name = df['ad copy format'][i]\n",
    "            \n",
    "                if i < len(df)-1:\n",
    "                    if df['rotation type'][i+1] == 'rotation type':\n",
    "                        base_name = base_name + ' / ' + str(df['ad copy format'][i+1])\n",
    "                else:\n",
    "                    base_name = df['ad copy format'][i]\n",
    "                df['merge_type_cells'][i] =  base_name\n",
    "    \n",
    "            # последняя строка является объединенной Сначала идет строка Баннеры - в ней все цифры\n",
    "            # Второая строка Универсальные баннеры - в ней нет значений потому что поставщик считает, что это одно и тоже\n",
    "            # мы убираем такие строки без данных\n",
    "            df = df[df['impressions']!='']\n",
    "            # передаем новое название формата в нужное нам поле\n",
    "            df['ad copy format'] = df['merge_type_cells']\n",
    "            df = df.drop('merge_type_cells', axis=1)\n",
    "            # добавляем поля с общей информацией\n",
    "            df['supplier'] = network\n",
    "            df['report_name'] = report_name\n",
    "            df['sheet_name'] = sheet_name\n",
    "            df['brand'] = brand\n",
    "            df['period'] = period\n",
    "            df['site/ssp'] = ''\n",
    "            df['placement'] = ''\n",
    "            df['budget_nds'] =(df['budget_without_nds'] * 1.2).astype('float').round(2)\n",
    "           \n",
    "            # парсим Гео и Соц. дем из поля targeting\n",
    "            df['geo'] = df['targeting'].apply(lambda x: get_targetings(x, 'гео:','\\n', flag='geo'))\n",
    "            df['soc_dem'] = df['targeting'].apply(lambda x: get_targetings(x, 'ца:','покупатели', flag='soc'))\n",
    "            \n",
    "            # если в этих полях встречаются пустые ячейки, то заменяем их на 0\n",
    "            df['vtr, %'] = df['vtr, %'].apply(replace_blank)\n",
    "            df['views'] = df['views'].apply(replace_blank)\n",
    "            # переставляем поля местами, чтобы все было единообразно\n",
    "            df = df[base_cols]\n",
    "            tmp_dict[sheet_name] = df\n",
    "\n",
    "    return pd.concat(tmp_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aeebd9-5b3c-43f8-909e-23455dc4b300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f0ad3f-2c12-4b94-8d28-bb1e0ac0ed74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8debac-646a-4ca1-8b96-8b234b53a2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a85ca-8504-4d3d-9416-a1148786e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'weborama'\n",
    "report_name = 'tst'\n",
    "tmp_dict = {}\n",
    "sheet_names = pd.ExcelFile(BytesIO(data_link))\n",
    "# в этом файле присутствуют скрытые листы\n",
    "# нам нужно исключить их из парсинга\n",
    "# поэтому добавляем дополнительный блок с проверкой статуса листа\n",
    "sheets = get_sheets_list(sheet_names, extention)\n",
    "for sheet in sheets:\n",
    "    sheet_name = check_excel_sheets(sheet, extention)\n",
    "    if sheet_name:\n",
    "        if 'banner' in sheet_name.lower() or 'video' in sheet_name.lower() \\\n",
    "        or 'баннер' in sheet_name.lower() or 'видео' in sheet_name.lower():\n",
    "            \n",
    "            df = pd.read_excel(BytesIO(data_link), sheet_name=sheet_name, header=None)\n",
    "            sheet_name = normalize_headers(sheet_name)\n",
    "            print(sheet_name)\n",
    "            # заголовки в файле состоят из 2-х строк, поэтому нужно выполнить заполнение вниз на 1 строку\n",
    "            # забираем название полей, в которых нужно сдвинуть строку вниз\n",
    "            ffill_columns = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "            df[ffill_columns] = df[ffill_columns].ffill(limit=1) # заполняем вниз\n",
    "            \n",
    "            # т.к. мы выполнили заполнение вниз на 1 строку\n",
    "            # у нас дублируются заголовки, поэтому мы берем второе вхождение забираем индекс начала таблицы\n",
    "            start_index = get_index_row(df, 1, 'период') + 1\n",
    "            # забираем название полей из файла\n",
    "            col_names_list = df.iloc[start_index].fillna('').apply(normalize_headers)\n",
    "            pattern = 'показы'\n",
    "            # получаем индекс колонки\n",
    "            col_index = get_col_index(col_names_list, pattern, flag='equals')\n",
    "            df[col_index] = df[col_index].fillna('0')\n",
    "            df = df.fillna('')\n",
    "\n",
    "            # сохраняем название бренда\n",
    "            brand = df[1].loc[get_index_row(df, 1, 'клиент')]\n",
    "            brand = brand[len('Клиент:'):].strip()\n",
    "            \n",
    "            # если целевая аудитория НЕ будет указана в самой таблице\n",
    "            # то возьмем значение из описания НАД таблицей\n",
    "            ca = df[1].loc[get_index_row(df, 1, 'ца')]\n",
    "            ca = ca[len('ЦА:'):].strip()\n",
    "            \n",
    "                        \n",
    "            # т.к. одно из полей может менять название, нам нужно его к единому стандарту\n",
    "            # сначала получим индекс колонки, которая нам нужна. она тоже может менять положение (может быть втоорой или третьей)\n",
    "            pattern = 'сервис'\n",
    "            # получаем индекс колонки\n",
    "            col_index = get_col_index(col_names_list, pattern)\n",
    "            # получаем индекс строки\n",
    "            # row_index = get_index_row(df, col_index, pattern) + 1\n",
    "            # меняем название в нужнй ячейке\n",
    "            df[col_index].loc[start_index] = 'source'\n",
    "            \n",
    "            # меняем назвние еще одного поля\n",
    "            pattern = 'объем'\n",
    "             # получаем индекс колонки\n",
    "            col_index = get_col_index(col_names_list, pattern)\n",
    "            # получаем индекс строки\n",
    "            # row_index = get_index_row(df, col_index, pattern) + 1\n",
    "            # меняем название в нужнй ячейке\n",
    "            df[col_index].loc[start_index] = 'budget_without_nds'\n",
    "\n",
    "            # меняем назвние еще одного поля\n",
    "            pattern = 'частота'\n",
    "             # получаем индекс колонки\n",
    "            col_index = get_col_index(col_names_list, pattern)\n",
    "            # получаем индекс строки\n",
    "            # row_index = get_index_row(df, col_index, pattern) + 1\n",
    "            # меняем название в нужнй ячейке\n",
    "            df[col_index].loc[start_index] = 'frequency'\n",
    "            \n",
    "            # задаем названия полей\n",
    "            df.columns = df.iloc[start_index].apply(normalize_headers) # забираем название полей из файла\n",
    "            # обрезаем верхнюю часть таблицы. она больше не нужна\n",
    "            df = df.iloc[start_index+1:].reset_index(drop=True)\n",
    "            # обрезаем таблицу снизу\n",
    "            end_index = get_index_row(df, 'показы', '0')\n",
    "            df = df.iloc[:end_index]\n",
    "            # создаем базовый список полей, которые есть всегда вне зависимости от типа размещения\n",
    "            standart_columns = ['период', 'source', 'формат рекламы', 'гео', 'аудиторные данные перечислены через слэш (/)',\n",
    "                            'стоимость за единицу (до ндс)', 'budget_without_nds', 'показы', 'охват', 'клики', 'frequency', 'модель закупки']\n",
    "            \n",
    "            # проверяем наличие Видео размещений. Если они есть, то используем дополнительные поля из таблицы\n",
    "            # если Видео размещений нет, то добавляем дополнительно 2 поля с 0 (это нужно для нормализации общей таблицы     \n",
    "            if 'vtr' not in list(df.columns):\n",
    "                df['views'] = 0\n",
    "                df['vtr'] = 0.0\n",
    "            else:\n",
    "                df['views'] = df['vtr'].astype('float') * df['показы'].astype('float')\n",
    "                \n",
    "            if 'ца' not in list(df.columns):\n",
    "                df['ца'] = ca\n",
    "\n",
    "            standart_columns += ['ца', 'views', 'vtr']\n",
    "            # оставляем только нужные поля\n",
    "            df = df[standart_columns]\n",
    "            # приводим названия полей к единому стандарту\n",
    "            df = df.rename(columns={'период': 'period', 'формат рекламы': 'ad copy format', 'гео': 'geo',\n",
    "                                    'аудиторные данные перечислены через слэш (/)': 'targeting', 'ца': 'soc_dem', \n",
    "                                    'модель закупки': 'rotation type', 'стоимость за единицу (до ндс)': 'unit price',\n",
    "                                    'показы': 'impressions', 'охват': 'reach', 'клики': 'clicks', 'vtr': 'vtr, %'})\n",
    "            df['supplier'] = network\n",
    "            df['report_name'] = report_name\n",
    "            df['sheet_name'] = sheet_name\n",
    "            df['brand'] = brand\n",
    "            df['site/ssp'] = ''\n",
    "            df['placement'] = ''\n",
    "            df['budget_nds'] =(df['budget_without_nds'] * 1.2).astype('float').round(2)\n",
    "            \n",
    "            df = df[base_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3866a21a-f448-4d80-8013-71fa14f049bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ba607-3e8b-41f7-8fb8-f18183b64d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adcfd2b-2050-4c4f-92f2-b67ee6d2c0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e44fac8-08d2-47b0-8b8d-ca83739b140c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9a80f5-6cd7-432d-833e-d96785732071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c5723-d01d-4827-a155-fb06d5ba61e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd3e13-dd62-4a1c-9c47-9b296199cb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7874af06-9604-4e0e-81c3-5b71e731bba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d98c2f-002b-416e-a500-56dca8d9038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_key = yandex_folders['public_key']  # из ответа Яндекс забираем public_key, чтобы использовать его для скачивания файлов\n",
    "\n",
    "for i in range(len(yandex_folders['_embedded']['items'])): # через цикл проходим по ответу Яндекса и забираем названия вложенных папок\n",
    "    file_type = yandex_folders['_embedded']['items'][i]['type']\n",
    "    if file_type=='dir':   # если находим файлы с типом dir (папка), то забираем путь к этой папке\n",
    "        folder_path = yandex_folders['_embedded']['items'][i]['path']\n",
    "        print(folder_path)\n",
    "        yandex_responce = get_yandex_disk_responce(base_public_url, public_key, folder_path) # отправляем запрос, чтобы получить содержимое папки\n",
    "\n",
    "        # Через цикл проходим по папке с файлами\n",
    "        # Нас интересуют файлы эксель. Причем каждая экселька будет парситься по своему, т.к. они относятся к разным рекламным площадкам\n",
    "        \n",
    "        # Проходим через цикл по содержимому папки (отдельный флайт)\n",
    "        for i in range(len(yandex_responce['_embedded']['items'])):\n",
    "            file_info = yandex_responce['_embedded']['items'][i]\n",
    "            if file_info['type']=='file':  # если документ является фалйом(не папкой или изображением), то забираем его название \n",
    "                file_name = file_info['name'] # сохраняем название файла\n",
    "                if 'pdf' in file_name: # еслит тип файла является xlsx, то уберем расширение и будем его использовать в качесвте названия отчета\n",
    "                    file_path = file_info['path']\n",
    "                    \n",
    "                    # report_name = '.'.join(file_name.split('.')[:-1]) # убираем .xlsx из названия файла\n",
    "                    print(file_name)\n",
    "                    res_file_link = get_yandex_disk_responce(download_url, public_key, file_path) # получаем ссылку на скачивание отчета\n",
    "                    download_response = requests.get(res_file_link['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618826eb-16a0-4e26-8616-95e51e0284f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_parse_pdf import *\n",
    "from pypdf import PdfReader\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d4fdc9-ab80-4eeb-8b98-1a28a039a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_link = download_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4f1909-22f0-47ac-b6f6-22034d4691bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = parse_pdf_benchmarks(data_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d5204-3709-4a1c-8aae-a37102fe8e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1cf456-836d-4768-986d-076f5622754b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163cc415-5d1f-4db2-a60a-d0337e65ec8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7061f529-1656-4d11-9ad6-d4e9268b683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdf_benchmarks(data_link):\n",
    "    main_dict = {}\n",
    "    # открываем PDF документ\n",
    "    reader = PdfReader(BytesIO(data_link))\n",
    "    # получаем кол-во страниц в документе\n",
    "    # проходим через цикл по всем страницам\n",
    "    print(len(reader.pages))\n",
    "    for num in range(len(reader.pages)):\n",
    "        # берем отдельную страницу \n",
    "        page = reader.pages[num]\n",
    "        # забираем из нее содержание\n",
    "        text = page.extract_text()\n",
    "        # пробуем выполнить парсинг данных\n",
    "        # - если получится, то вернем датаФрейм\n",
    "        # - иначе пропускаем страницу, на которой возникает ошибка парсинга\n",
    "        try:\n",
    "            # забираем заголовок таблицы на странице (здесь указывается тип рекламы и категории - VK Реклама в категории авто)\n",
    "            report_name_index = text.find('\\n')\n",
    "            report_name = text[:report_name_index].lower()\n",
    "            # забираем период в отношении, которого действуют бенчмарки\n",
    "            period_row_index = text.find('\\n', text.find('\\n')+1)\n",
    "            period_row = text[report_name_index+1: period_row_index]\n",
    "            first_digit_period = re.search('(\\d+)', period_row).group()\n",
    "            first_digit_index = period_row.find(first_digit_period)\n",
    "            period = period_row[first_digit_index:]\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        # если в заголовке страницы содержится инфо о отм, что на странице присутствует инфо о бенчмарках, то продолжаем парсинг\n",
    "        if 'бенчмарки' in report_name and ('vk' in report_name or 'mytarget' in report_name or 'вконтакте' in report_name):\n",
    "            if 'vk' in report_name:\n",
    "                print(report_name)\n",
    "                source = 'VK Ads'\n",
    "                df_tmp = get_parse_vk_benchmarks(text, report_name, period, source)\n",
    "                main_dict[report_name] = df_tmp\n",
    "            elif 'mytarget' in report_name or 'вконтакте':\n",
    "                print(report_name)\n",
    "                if 'mytarget' in report_name:\n",
    "                    source = 'MyTarget'\n",
    "                else:\n",
    "                    source = 'Vkontakte'\n",
    "                df_tmp = get_parse_mytarget_benchmarks(text, report_name, period, source)\n",
    "                main_dict[report_name] = df_tmp\n",
    "\n",
    "    return pd.concat(main_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf09979-61b5-480c-af5c-f23721333c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4f6c5f-a7be-4690-b4fe-301982da04e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
